## HFT 低延迟底层优化

我们的核心目标是追求**最低延迟 (Latency)** 和最高的**确定性 (Determinism)**，即**最低抖动 (Jitter)**。

### I. 🎯 核心概念：延迟与抖动

| 概念               | 定义                    | 优化目标                       |
|:---------------- |:--------------------- |:-------------------------- |
| **延迟 (Latency)** | 市场数据接收到订单发出的**平均时间**。 | 越低越好（微秒 $\rightarrow$ 纳秒）。 |
| **抖动 (Jitter)**  | 延迟的**变动性/不一致性**。      | 必须消除，以确保交易逻辑的**可预测性**。     |

---

### II. ⚙️ 内核旁路技术 (Kernel Bypass)

目标：绕过通用操作系统内核处理网络数据的巨大开销和不确定性。

| 机制                             | 目的                | 原理                                  | 优势                               |
|:------------------------------ |:----------------- |:----------------------------------- |:-------------------------------- |
| **轮询 (Polling)**               | 代替中断 (Interrupt)。 | 独占 CPU 核心持续检查网卡数据，**避免上下文切换**。      | 消除上下文切换带来的高 Jitter。              |
| **零拷贝 (Zero-Copy)**            | 避免数据在内核/应用层之间的拷贝。 | 利用 **DMA** 将网卡数据直接写入应用层内存。          | **减少延迟**和**释放 CPU 周期**给策略执行。     |
| **OpenOnload**                 | 低侵入性内核旁路。         | 在用户空间实现 TCP/IP 栈，加速标准 POSIX Socket。 | 易于部署，适用于需要标准协议的场景。               |
| **DPDK (Data Plane Dev. Kit)** | 极致裸包处理。           | 完全接管网卡，直接在用户空间处理 Ethernet 帧。        | **最低纳秒级延迟**，常用于对速度要求最高的**订单执行**。 |

---

### III. 💻 操作系统与 BIOS 精调

目标：通过禁用所有节能和通用功能，确保 CPU 始终处于最高速且稳定的状态。

| 优化项                       | 禁用或锁定的原因                | Jitter 来源                             | 解决方案                                |
|:------------------------- |:----------------------- |:------------------------------------- |:----------------------------------- |
| **超线程 (Hyper-Threading)** | 共享 L1/L2 缓存，导致**缓存污染**。 | **缓存争用**，策略数据被驱逐。                     | **BIOS 禁用**超线程。                     |
| **CPU 亲和性 (Affinity)**    | OS 可能将进程**迁移**到不同核心。    | **进程迁移**导致的**冷缓存**惩罚 (数百 $ns$)。       | 使用 `taskset` 等工具将进程**绑定**到独占的核心。    |
| **C-states**              | CPU 进入休眠状态（C1, C3, C6）。 | **休眠唤醒**需要 $100-200 \mu s$ 的**致命延迟**。 | **BIOS 禁用**所有 C-states，强制 C0 (全速)。  |
| **P-states**              | CPU 动态调整频率和电压。          | **频率波动**导致代码执行时间**不确定**。              | OS 设置 `performance` 调节器，**锁定**最高频率。 |

---

### IV. 🚀 专用硬件加速 (FPGA)

目标：将延迟降低到**纳秒级 (ns)** 的物理极限，实现最稳定的确定性处理。

| 机制                   | FPGA 优势           | 消除的 CPU 软件开销                         | 物理原理                                                                       |
|:-------------------- |:----------------- |:------------------------------------ |:-------------------------------------------------------------------------- |
| **硬件流水线**            | 将交易逻辑固化为**物理电路**。 | **分支误预测**（每次 $10-50 \text{ ns}$ 惩罚）。 | 数据流过电路，**无指令周期**，延迟由**信号传播速度**决定。                                          |
| **Block RAM (BRAM)** | 极快速、确定性内存。        | **L1/L2 缓存未命中**导致的延迟尖峰。              | 内存**内嵌**于逻辑单元旁，**一周期访问**，无缓存层次结构。                                          |
| **物理距离限制**           | 延迟受限于光速。          | N/A                                  | 信号在传输介质中的速度约为光速的 $2/3$。**$10 \text{ 米}$ 额外距离 $\approx 50 \text{ ns}$ 延迟**。 |



---

## 📜 协议与网络优化总结

### I. 协议选择：UDP/Multicast vs. TCP

高频交易系统在接收**市场数据 (Market Data)** 时，几乎总是依赖于 **UDP (用户数据报协议)**，并采用 **IP 多播 (Multicast)** 的形式。

#### A. 为什么排除 TCP？

TCP 为了实现“可靠性”和“顺序性”所做的额外工作，会给 HFT 带来致命的延迟和抖动：

| **TCP 机制**                       | **负面影响**                         | **HFT 结论**                      |
| -------------------------------- | -------------------------------- | ------------------------------- |
| **三次握手**                         | 引入启动延迟。                          | **得不偿失**：浪费宝贵的初始时间。             |
| **重传机制**                         | 丢包后等待超时并重传，引入**数百毫秒**的巨大 Jitter。 | **无法接受**：市场数据时效性极强，旧数据无用。       |
| **队头阻塞 (Head-of-Line Blocking)** | 一个丢失的包会**阻塞**后续所有已到达的数据包。        | **致命**：强制系统等待已过时的数据，导致策略永远慢人一步。 |

#### B. 为什么选择 UDP/Multicast？

| **协议**        | **目的**            | **优势**                                               |
| ------------- | ----------------- | ---------------------------------------------------- |
| **UDP**       | 追求**速度**，无连接、无流控。 | **最低延迟**：无握手、无重传、无拥塞控制开销。                            |
| **Multicast** | 追求**效率**（“一对多”）。  | **节省带宽**：交易所只需发送一份数据包。**降低网络延迟**：利用交换机硬件进行快速数据复制和分发。 |

---

### II. 架构设计：速度与可靠性的权衡

由于 UDP 不可靠，HFT 采用 **双路径架构 (Dual Path)** 来同时保证速度和数据完整性。

| **路径**               | **协议**        | **目的**             | **机制**                            |
| -------------------- | ------------- | ------------------ | --------------------------------- |
| **主路径 (Fast Path)**  | UDP/Multicast | **实时速度**（用于即时决策）。  | 客户端高速接收带**序列号**的数据。               |
| **辅助路径 (Slow Path)** | TCP 或可靠 UDP   | **数据可靠性**（用于回填校验）。 | 检测到序列号跳跃后，向**重传服务器**请求丢失的数据包（回填）。 |

**关键点：** 即使在 Slow Path 发生回填时，HFT 系统**不会停止**处理 Fast Path 的新数据，确保策略总是基于**最新**的信息。

---

### III. 物理优化：微突发管理 (Micro-Burst Management)

目标：通过优化网络设备，消除短时突发流量导致的丢包和 Jitter。

| **问题**                | **现象**           | **后果**                                   | **解决方案**                       |
| --------------------- | ---------------- | ---------------------------------------- | ------------------------------ |
| **微突发 (Micro-Burst)** | 极短时间内大量数据包涌入交换机。 | **缓冲区溢出**和**丢包**，导致需要重传和巨大 Jitter。       | 采用**深度缓冲区 (Deep Buffer)** 交换机。 |
| **深度缓冲区**             | N/A              | 牺牲极微小的平均延迟，**消除**因丢包导致的**延迟尖峰**（Jitter）。 | 数据包被排队而不是被丢弃，保证了**延迟的确定性**。    |





## 🧠 应用层代码与内存优化总结

### I. CPU 缓存优化：保证速度与确定性

核心思想是最大化 **L1/L2 缓存命中率**，并遵循 **局部性原则**。

| **优化项**                | **目标**          | **核心原理**                                                                                        | **优势**                                                       |
| ---------------------- | --------------- | ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------ |
| **空间局部性**              | 确保相关数据被同时加载。    | 数据结构应设计为**内存连续存放**（避免基于指针的链表）。访问第一个字段时，**整个 $64 \text{ 字节}$ 缓存行**被加载。                           | 访问速度从主内存的 $\sim 100 \text{ ns}$ 降到 L1 的 $\sim 1 \text{ ns}$。 |
| **内存对齐**               | 确保数据对象不跨越缓存行边界。 | 使用 `alignas(64)` 确保数据结构与 $64 \text{ 字节}$ 边界对齐。                                                  | 保证数据能被**单次、最快**地从缓存中读取，避免二次加载。                               |
| **数据预取 (Prefetching)** | 隐藏内存加载延迟。       | 使用 CPU 指令（如 `_mm_prefetch`）**提前**将预测要使用的数据从 DRAM 加载到缓存中。                                        | 将等待延迟**隐藏**在当前计算之后，提高确定性。                                    |
| **结构优化**               | 优化批量计算性能。       | 使用 **SoA (Structure of Arrays)** 结构（例如：`Price[N], Qty[N]...`）而不是 AoS，以提高对同一字段进行批量操作时的**空间局部性**。 |                                                              |

---

### II. 多线程同步：无锁编程 (Lock-Free)

目标：消除互斥锁（Mutex）带来的致命**上下文切换**开销和 $1-10 \mu s$ 的 Jitter。

| **机制**                     | **目的**        | **原理**                                    | **优势**                             |
| -------------------------- | ------------- | ----------------------------------------- | ---------------------------------- |
| **避免 Mutex**               | 消除 OS 内核介入。   | Mutex 竞争失败会导致线程**挂起**（Suspend）和**上下文切换**。 | Jitter **消除**：避免 $\mu s$ 级别的延迟尖峰。  |
| **CAS (Compare-and-Swap)** | 无锁数据结构的基础。    | **硬件原子指令**：尝试更新前先检查值是否被其他线程修改，确保操作的原子性。   | 保证同步的延迟是**纳秒级**且**可预测**。           |
| **自旋等待 (Spin-Wait)**       | 处理 CAS 失败的情况。 | 线程在 CAS 失败后**立即重试**，而不是被 OS 挂起。           | **避免上下文切换**开销，保持 L1/L2 缓存的**热状态**。 |

### III. 深入并发与内存管理

| **挑战**                  | **解决方案**                     | **作用**                                                    |
| ----------------------- | ---------------------------- | --------------------------------------------------------- |
| **伪共享 (False Sharing)** | **缓存行填充 (Padding)**。         | 在不共享的变量之间插入填充字节，确保它们相隔 $64 \text{ 字节}$，消除**不必要的缓存一致性开销**。 |
| **NUMA 架构**             | **NUMA 亲和性**。                | 使用 `numactl` 将进程、CPU 核心和**内存分配**绑定到**同一个 NUMA 节点**。       |
| **ABA 问题**              | **版本计数器 (Version Counter)**。 | 在 CAS 变量中添加一个版本号。确保即使值相同，但版本号不同，CAS 也会失败，保证无锁结构的正确性。      |

这些优化手段共同作用，将 HFT 策略的执行延迟推向了 CPU 硬件的极限。